{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from random import random\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../preprocessing/temporary_preprocessing_pipeline.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load and divide data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide training set into inputs and targets\n",
    "input_features = final_df_train[final_df_train.columns[:-2]]\n",
    "targets = final_df_train[final_df_train.columns[-2:]]\n",
    "\n",
    "# Divide dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_features, targets, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " def evaluate_abs_mse(train_rf_predictions,y_train,rf_predictions,y_test): # Pass raw predictions to function\n",
    "    pred_list_train = train_rf_predictions.tolist()\n",
    "    target_list_train = y_train.tolist()\n",
    "\n",
    "    pred_list_test = rf_predictions.tolist()\n",
    "    target_list_test = y_test.tolist()\n",
    "\n",
    "    print(f'Absolute mean square error on training set: {mean_absolute_error(target_list_train, pred_list_train)*2}')\n",
    "    print(f'Absolute mean square error on test set: {mean_absolute_error(pred_list_test, target_list_test)*2}')\n",
    "    return '-------------- Evaluated --------------'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model (takes a while)\n",
    "rfc = RandomForestClassifier(n_estimators=4500, \n",
    "                               max_features = 'sqrt',\n",
    "                               n_jobs=-1, verbose = 0)\n",
    "\n",
    "# Train model\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameter evaluation\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "\n",
    "for ind_tree in rfc.estimators_:\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing model\n",
    "train_rf_predictions = rfc.predict(X_train)\n",
    "train_rf_probs = rfc.predict_proba(X_train)\n",
    "\n",
    "rf_predictions = rfc.predict(X_test)\n",
    "rf_probs = rfc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse values to original values in euros\n",
    "test_rf_predictions = min_max_scaler_targets.inverse_transform(rf_predictions)\n",
    "train_rf_predictions = min_max_scaler_targets.inverse_transform(train_rf_predictions)\n",
    "\n",
    "y_train = min_max_scaler_targets.inverse_transform(y_train)\n",
    "y_test = min_max_scaler_targets.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_abs_mse(train_rf_predictions,y_train,test_rf_predictions,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=90, max_features='sqrt', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=800, n_jobs=-1, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model (takes a while)\n",
    "rfr = RandomForestRegressor(n_estimators= 800,\n",
    "                            min_samples_split= 5,\n",
    "                            min_samples_leaf= 1,\n",
    "                            max_features= 'sqrt',\n",
    "                            max_depth= 90,\n",
    "                            bootstrap= False,\n",
    "                            n_jobs=-1,\n",
    "                            verbose = 0)\n",
    "\n",
    "# Train model\n",
    "rfr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of nodes 409\n",
      "Average maximum depth 26\n"
     ]
    }
   ],
   "source": [
    "# Model parameter evaluation\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "\n",
    "for ind_tree in rfr.estimators_:\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "test_rfr_predictions = rfr.predict(X_test)\n",
    "train_rfr_predictions = rfr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse values to original values in euros\n",
    "test_rfr_predictions = min_max_scaler_targets.inverse_transform(test_rfr_predictions)\n",
    "train_rfr_predictions = min_max_scaler_targets.inverse_transform(train_rfr_predictions)\n",
    "\n",
    "y_train_reversed = min_max_scaler_targets.inverse_transform(y_train)\n",
    "y_test_reversed = min_max_scaler_targets.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute mean square error on training set: 114.93737472766861\n",
      "Absolute mean square error on test set: 340.5613725490201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'-------------- Evaluated --------------'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_abs_mse(train_rfr_predictions,y_train_reversed,test_rfr_predictions,y_test_reversed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test models on real test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on real test data\n",
    "final_predictions = rfr.predict(final_df_test)\n",
    "final_predictions_reversed = min_max_scaler_targets.inverse_transform(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_prices = pd.DataFrame(final_predictions_reversed, columns = targets.columns)\n",
    "submission = pd.concat([pd.DataFrame(df_laptops_test['id']), submission_prices], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write final df to csv\n",
    "submission.to_csv(r'../../data/intermediate_submission_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': False,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'mse',\n",
      " 'max_depth': 90,\n",
      " 'max_features': 'sqrt',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 5,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 800,\n",
      " 'n_jobs': -1,\n",
      " 'oob_score': False,\n",
      " 'random_state': None,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rfr.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 130 candidates, totalling 520 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 520 out of 520 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=Fals...\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rfr3 = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rfr3, param_distributions = random_grid, n_iter = 130, cv = 4, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 20,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute mean square error on training set: 118.36272617794435\n",
      "Absolute mean square error on test set: 354.75540609199754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'-------------- Evaluated --------------'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rfr_predictions = rf_random.predict(X_test)\n",
    "train_rfr_predictions = rf_random.predict(X_train)\n",
    "\n",
    "test_rfr_predictions = min_max_scaler_targets.inverse_transform(test_rfr_predictions)\n",
    "train_rfr_predictions = min_max_scaler_targets.inverse_transform(train_rfr_predictions)\n",
    "\n",
    "y_train = min_max_scaler_targets.inverse_transform(y_train)\n",
    "y_test = min_max_scaler_targets.inverse_transform(y_test)\n",
    "\n",
    "evaluate_abs_mse(train_rfr_predictions,y_train,test_rfr_predictions,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AAB_Ass_2",
   "language": "python",
   "name": "aab_assignment_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
