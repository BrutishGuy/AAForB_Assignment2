{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from random import random\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_laptops_test = pd.read_csv(r\"../../data/test.csv\", sep=',')\n",
    "df_laptops_train = pd.read_csv(r\"../../data/train.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data and solving missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all touchscreen values to lower case letters (f.ex: from 'Glossy' --> 'glossy')\n",
    "def lower_case_screen(df):\n",
    "    return df['screen_surface'].replace({'Glossy': 'glossy', 'Matte': 'matte'}, inplace=True)\n",
    "\n",
    "lower_case_screen(df_laptops_train)\n",
    "lower_case_screen(df_laptops_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Detect missing values\n",
    "def detect_and_fill_all_missing_values_with_correct_nan(df):\n",
    "    df.fillna(value=np.nan,inplace=True)\n",
    "\n",
    "detect_and_fill_all_missing_values_with_correct_nan(df_laptops_train)\n",
    "detect_and_fill_all_missing_values_with_correct_nan(df_laptops_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN screen_surface values with 'glossy' or 'matte' at random\n",
    "def replace_nan_screen_surface(df):\n",
    "    for i in range(0,len(df)):\n",
    "        if type(df.screen_surface[i]) == float:\n",
    "            if random() >= 0.5:\n",
    "                df.at[i,'screen_surface'] = 'glossy'\n",
    "            else:\n",
    "                df.at[i,'screen_surface'] = 'matte'\n",
    "\n",
    "replace_nan_screen_surface(df_laptops_train)\n",
    "replace_nan_screen_surface(df_laptops_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace weight missing values by the median of all the weights\n",
    "def replace_weight_nans_with_median(df):\n",
    "    df['weight'] = df['weight'].fillna(value=df['weight'].median())\n",
    "\n",
    "replace_weight_nans_with_median(df_laptops_train)\n",
    "replace_weight_nans_with_median(df_laptops_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing OS and OS_details based on brand\n",
    "def replace_missing_os_and_os_details(df):\n",
    "    for i in range(0,len(df)):\n",
    "        if type(df.os[i]) == float:        # When the value is missing\n",
    "            if 'apple' in df.brand[i].lower():\n",
    "                df.at[i,'os_details'] = 'macOS Catalina'\n",
    "                df.at[i,'os'] = 'macOS'\n",
    "            else:\n",
    "                df.at[i,'os_details'] = 'Windows'\n",
    "                df.at[i,'os'] = 'Windows 10'\n",
    "                \n",
    "replace_missing_os_and_os_details(df_laptops_train)\n",
    "replace_missing_os_and_os_details(df_laptops_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_last_missing_values(df):\n",
    "    # Make index and column arrays to then use in the creation of the new df\n",
    "    index_array = np.array(range(0,len(df)))\n",
    "    column_names_array = np.array(list(df.columns), dtype=object)\n",
    "    \n",
    "    # replace rest of missing values with most frequent simple imputer\n",
    "    imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "    temp_array = imp.fit_transform(df)\n",
    "\n",
    "    no_nulls_df = pd.DataFrame(data=temp_array[0:,0:],index=index_array, columns=column_names_array)\n",
    "    \n",
    "    return no_nulls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_nulls_train = resolve_last_missing_values(df_laptops_train)\n",
    "no_nulls_test = resolve_last_missing_values(df_laptops_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unimportant columns\n",
    "def remove_unimportant_columns(df):\n",
    "    return df.drop(columns = ['id',\n",
    "                              'name',         # Name information is to be found in other columns\n",
    "                              'base_name',    # Base name is partially in brand\n",
    "                              'os',           # OS_details is more important\n",
    "                              'discrete_gpu', # Information contained in GPU information\n",
    "                              'cpu_details']) # Only CPU column is good\n",
    "\n",
    "train_df = remove_unimportant_columns(no_nulls_train)\n",
    "test_df = remove_unimportant_columns(no_nulls_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode glossy and matte as 1 and 0 respectively\n",
    "def dummy_encode_screen_surface(df):\n",
    "    for i in range(0,len(df)):\n",
    "        if df.screen_surface[i] == 'glossy':\n",
    "            df.at[i,'screen_surface'] = 1\n",
    "        else:\n",
    "            df.at[i,'screen_surface'] = 0\n",
    "\n",
    "dummy_encode_screen_surface(train_df)\n",
    "dummy_encode_screen_surface(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_data_cat_and_num(df):\n",
    "    if 'min_price' in df.columns:\n",
    "        df_num = df[['screen_size', \n",
    "                     'pixels_x', \n",
    "                     'pixels_y', \n",
    "                     'screen_surface', \n",
    "                     'touchscreen', \n",
    "                     'detachable_keyboard', \n",
    "                     'ram', \n",
    "                     'ssd',\n",
    "                     'storage',\n",
    "                     'weight',\n",
    "                     'min_price',\n",
    "                     'max_price']].astype('int')\n",
    "    else:\n",
    "        df_num = df[['screen_size', \n",
    "                     'pixels_x', \n",
    "                     'pixels_y', \n",
    "                     'screen_surface', \n",
    "                     'touchscreen', \n",
    "                     'detachable_keyboard', \n",
    "                     'ram', \n",
    "                     'ssd',\n",
    "                     'storage',\n",
    "                     'weight']].astype('int')\n",
    "\n",
    "    df_cat = df[['brand',\n",
    "                 'cpu', \n",
    "                 'gpu', \n",
    "                 'os_details']]\n",
    "    return df_num, df_cat\n",
    "\n",
    "train_num, train_cat = divide_data_cat_and_num(train_df)\n",
    "test_num, test_cat = divide_data_cat_and_num(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode all categorical variables\n",
    "def one_hot_encode(df_train_categories, df_test_categories):\n",
    "    full_enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    full_enc.fit(df_train_categories.to_numpy())\n",
    "    \n",
    "    full_transform_train = full_enc.transform(df_train_categories.to_numpy()).toarray()\n",
    "    full_transform_test = full_enc.transform(df_test_categories.to_numpy()).toarray()\n",
    "    \n",
    "    full_transform_train_df = pd.DataFrame(full_transform_train, columns = full_enc.get_feature_names())\n",
    "    full_transform_test_df = pd.DataFrame(full_transform_test, columns = full_enc.get_feature_names())\n",
    "    \n",
    "    return full_transform_train_df, full_transform_test_df\n",
    "\n",
    "train_cat_ohe, test_cat_ohe = one_hot_encode(train_cat, test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all numerical variables\n",
    "def normalize(train_num, test_num):\n",
    "    \n",
    "    train_num_inputs = train_num[train_num.columns[:-2]]\n",
    "    train_targets = train_num[train_num.columns[-2:]]\n",
    "    test_num_inputs = test_num\n",
    "    \n",
    "    # Fit one min_max scaler for numerical inputs and one for targets\n",
    "    min_max_scaler_inputs = preprocessing.MinMaxScaler()\n",
    "    min_max_scaler_inputs.fit(train_num_inputs.values)\n",
    "    \n",
    "    min_max_scaler_targets = preprocessing.MinMaxScaler()\n",
    "    \n",
    "    train_scaled = min_max_scaler_inputs.transform(train_num_inputs.values)\n",
    "    test_scaled = min_max_scaler_inputs.transform(test_num_inputs.values)\n",
    "    targets_scaled = min_max_scaler_targets.fit_transform(train_targets.values)\n",
    "    \n",
    "    # Make final dataframes\n",
    "    train_norm = pd.DataFrame(train_scaled, columns = train_num_inputs.columns)\n",
    "    target_norm = pd.DataFrame(targets_scaled, columns = train_targets.columns)\n",
    "    test_norm = pd.DataFrame(test_scaled, columns = test_num_inputs.columns)\n",
    "    \n",
    "    return train_norm, target_norm, test_norm, min_max_scaler_targets\n",
    "\n",
    "train_norm, target_norm, test_norm, min_max_scaler_targets = normalize(train_num,test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring normalized and one-hot-encoded data together\n",
    "final_df_train = pd.concat([train_norm, train_cat_ohe, target_norm], axis=1)\n",
    "final_df_test = pd.concat([test_norm, test_cat_ohe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write final dfs to csv\n",
    "final_df_train.to_csv(r'../../data/preprocessed_data_train.csv', index = False)\n",
    "final_df_test.to_csv(r'../../data/preprocessed_data_test.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AAB_Ass_2",
   "language": "python",
   "name": "aab_assignment_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
