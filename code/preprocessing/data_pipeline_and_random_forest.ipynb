{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#------------------------------------------------------------------------------\n",
    "### STEP 0: INITIALIZE LIBRARIES\n",
    "#------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from random import random\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_laptops_original = pd.read_csv(\"../data/train.csv\", sep=';')\n",
    "df_laptops = df_laptops_original.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data and solving missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all touchscreen values to lower case letters (f.ex: from 'Glossy' --> 'glossy')\n",
    "df_laptops['screen_surface'].replace({'Glossy': 'glossy', 'Matte': 'matte'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['screen_surface', 'cpu_details', 'detachable_keyboard', 'gpu', 'os',\n",
       "       'os_details', 'weight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detect missing values\n",
    "df_laptops.fillna(value=np.nan,inplace=True)\n",
    "null_data = df_laptops[df_laptops.isnull().any(axis=1)]\n",
    "df_laptops.columns[df_laptops.isnull().any()]  # ['screen_surface', 'cpu_details', 'detachable_keyboard', 'gpu', 'os', ...\n",
    "       # 'os_details', 'weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN screen_surface values with 'glossy' or 'matte' at random\n",
    "for i in range(0,len(df_laptops)):\n",
    "    if type(df_laptops.screen_surface[i]) == float:\n",
    "        if random() >= 0.5:\n",
    "            df_laptops.at[i,'screen_surface'] = 'glossy'\n",
    "        else:\n",
    "            df_laptops.at[i,'screen_surface'] = 'matte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace weight missing values by the median of all the weights\n",
    "df_laptops['weight'] = df_laptops['weight'].fillna(value=df_laptops['weight'].median());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing OS and OS_details based on brand\n",
    "for i in range(0,len(df_laptops)):\n",
    "    if type(df_laptops.os[i]) == float:        # When the value is missing\n",
    "        if 'apple' in df_laptops.brand[i].lower():\n",
    "            df_laptops.at[i,'os_details'] = 'macOS Catalina'\n",
    "            df_laptops.at[i,'os'] = 'macOS'\n",
    "        else:\n",
    "            df_laptops.at[i,'os_details'] = 'Windows'\n",
    "            df_laptops.at[i,'os'] = 'Windows 10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_laptops.describe()\n",
    "# Make index and column arrays to then use in the creation of the new df\n",
    "index_array = np.array(range(0,len(df_laptops)))\n",
    "column_names_array = np.array(list(df_laptops.columns), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replace rest of missing values with most frequent simple imputer\n",
    "imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "temp_array = imp.fit_transform(df_laptops)\n",
    "\n",
    "no_nulls_df = pd.DataFrame(data=temp_array[0:,0:],index=index_array, columns=column_names_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last missing values check\n",
    "null_data = no_nulls_df[no_nulls_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering to-do's (just ideas)\n",
    "- Partition screen sizes to big-medium-small\n",
    "    - Small\tif pixels 640px or less\tand screen size: 4\" to 6\"; 20\" to 65\"\n",
    "    - Medium if pixels 641px to 1007px and screen size: 7\" to 12\"\n",
    "    - Large if pixels 1008px or greater and screen size: 13\" and larger\n",
    "- Divide 'cpu' column in cpu_brand (=AMD/Intel) and cpu_spec (=i7/i5/... for Intel or Pentium/Celeron/Ryzen/A8... for AMD)\n",
    "- Divide GPU column in Intel/NVIDIA/AMD and for NVIDIA and AMD levels according to their series \n",
    "    - f.ex: (NVIDIA --> 20/16/10/900M/..., RADEON --> RX 5000/VII/RX VEGA/...)\n",
    "- Find a suitable brand ranking\n",
    "- Divide weight up in high/medium/low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>screen_size</th>\n",
       "      <th>pixels_x</th>\n",
       "      <th>pixels_y</th>\n",
       "      <th>screen_surface</th>\n",
       "      <th>touchscreen</th>\n",
       "      <th>cpu</th>\n",
       "      <th>detachable_keyboard</th>\n",
       "      <th>gpu</th>\n",
       "      <th>os_details</th>\n",
       "      <th>ram</th>\n",
       "      <th>ssd</th>\n",
       "      <th>storage</th>\n",
       "      <th>weight</th>\n",
       "      <th>min_price</th>\n",
       "      <th>max_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>glossy</td>\n",
       "      <td>1</td>\n",
       "      <td>Intel Core i7</td>\n",
       "      <td>0</td>\n",
       "      <td>Intel HD</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>4.6</td>\n",
       "      <td>899</td>\n",
       "      <td>899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Razer</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>matte</td>\n",
       "      <td>0</td>\n",
       "      <td>Intel Core i7</td>\n",
       "      <td>0</td>\n",
       "      <td>NVIDIA GeForce RTX 2070 Max-Q</td>\n",
       "      <td>Windows 10 Home</td>\n",
       "      <td>16</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>4.63</td>\n",
       "      <td>2099.99</td>\n",
       "      <td>2099.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1366</td>\n",
       "      <td>768</td>\n",
       "      <td>matte</td>\n",
       "      <td>0</td>\n",
       "      <td>AMD A6</td>\n",
       "      <td>0</td>\n",
       "      <td>AMD Radeon R4</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>4.63</td>\n",
       "      <td>439</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acer</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>matte</td>\n",
       "      <td>0</td>\n",
       "      <td>Intel Core i3</td>\n",
       "      <td>0</td>\n",
       "      <td>Intel UHD 620</td>\n",
       "      <td>Windows 10 Home</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>5.3</td>\n",
       "      <td>375</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1600</td>\n",
       "      <td>900</td>\n",
       "      <td>glossy</td>\n",
       "      <td>0</td>\n",
       "      <td>Intel Core i5</td>\n",
       "      <td>0</td>\n",
       "      <td>Intel HD 620</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>5.8</td>\n",
       "      <td>559</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    brand screen_size pixels_x pixels_y screen_surface touchscreen  \\\n",
       "0  Lenovo        15.6     1920     1080         glossy           1   \n",
       "1   Razer        15.6     1920     1080          matte           0   \n",
       "2      HP        15.6     1366      768          matte           0   \n",
       "3    Acer        15.6     1920     1080          matte           0   \n",
       "4      HP        17.3     1600      900         glossy           0   \n",
       "\n",
       "             cpu detachable_keyboard                            gpu  \\\n",
       "0  Intel Core i7                   0                       Intel HD   \n",
       "1  Intel Core i7                   0  NVIDIA GeForce RTX 2070 Max-Q   \n",
       "2         AMD A6                   0                  AMD Radeon R4   \n",
       "3  Intel Core i3                   0                  Intel UHD 620   \n",
       "4  Intel Core i5                   0                   Intel HD 620   \n",
       "\n",
       "        os_details ram  ssd storage weight min_price max_price  \n",
       "0       Windows 10   8    0    1000    4.6       899       899  \n",
       "1  Windows 10 Home  16  512     512   4.63   2099.99   2099.99  \n",
       "2       Windows 10   8    0     500   4.63       439       449  \n",
       "3  Windows 10 Home   6    0    1000    5.3       375       449  \n",
       "4       Windows 10   8    0    1000    5.8       559       559  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unimportant columns\n",
    "most_important_features_df = no_nulls_df.copy()\n",
    "most_important_features_df = most_important_features_df.drop(columns = ['id',\n",
    "                                                                        'name',         # Name information is to be found in other columns\n",
    "                                                                        'base_name',    # Base name is partially in brand\n",
    "                                                                        'os',           # OS_details is more important\n",
    "                                                                        'discrete_gpu', # Information contained in GPU information\n",
    "                                                                        'cpu_details']) # Only CPU column is good\n",
    "most_important_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "temp_df = most_important_features_df\n",
    "# df_brand = pd.DataFrame({'brand':list(temp_df.brand.unique())})\n",
    "\n",
    "# Encode glossy and matte as 1 and 0 respectively\n",
    "for i in range(0,len(temp_df)):\n",
    "    if temp_df.screen_surface[i] == 'glossy':\n",
    "        temp_df.at[i,'screen_surface'] = 1\n",
    "    else:\n",
    "        temp_df.at[i,'screen_surface'] = 0\n",
    "\n",
    "# pd.get_dummies(df_brand,prefix=['brand'])\n",
    "brand_df = pd.get_dummies(temp_df['brand'],prefix='brand')\n",
    "cpu_df = pd.get_dummies(temp_df['cpu'],prefix='cpu')\n",
    "gpu_df = pd.get_dummies(temp_df['gpu'],prefix='gpu')\n",
    "os_df = pd.get_dummies(temp_df['os_details'],prefix='os_details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([brand_df, cpu_df, gpu_df, os_df, temp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnesecary columns\n",
    "final_df = final_df.drop(['brand', 'cpu', 'gpu', 'os_details'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide training set into inputs and targets\n",
    "input_features = final_df[list(final_df.columns)[:-2]]\n",
    "targets = final_df[list(final_df.columns)[-2:]]\n",
    "\n",
    "# Divide dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_features, targets, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with 100 trees\n",
    "model = RandomForestClassifier(n_estimators=4500, \n",
    "                               max_features = 'sqrt',\n",
    "                               n_jobs=-1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 4500 out of 4500 | elapsed:   28.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=4500,\n",
       "                       n_jobs=-1, oob_score=False, random_state=None, verbose=1,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of nodes 505\n",
      "Average maximum depth 29\n"
     ]
    }
   ],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "\n",
    "for ind_tree in model.estimators_:\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=4)]: Done 4500 out of 4500 | elapsed:   26.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=4)]: Done 4500 out of 4500 | elapsed:   24.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=4)]: Done 4500 out of 4500 | elapsed:    6.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=4)]: Done 4500 out of 4500 | elapsed:    7.1s finished\n"
     ]
    }
   ],
   "source": [
    "train_rf_predictions = model.predict(X_train)\n",
    "train_rf_probs = model.predict_proba(X_train)\n",
    "\n",
    "rf_predictions = model.predict(X_test)\n",
    "rf_probs = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357.5257843137254"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " def evaluate(train_rf_predictions,y_train,rf_predictions,y_test): # Pass raw predictions to function\n",
    "    pred_list_train = train_rf_predictions.tolist()\n",
    "    target_list_train = y_train.values.tolist()\n",
    "\n",
    "    pred_list_test = rf_predictions.tolist()\n",
    "    target_list_test = y_test.values.tolist()\n",
    "\n",
    "    print(f'Absolute mean square error on training set: {mean_absolute_error(target_list_train, pred_list_train)*2}')\n",
    "    print(f'Absolute mean square error on test set: {mean_absolute_error(pred_list_test, target_list_test)*2}')\n",
    "    return '-------------- Evaluated --------------'\n",
    "\n",
    "# Extra caution:\n",
    "sum_errors_max = 0\n",
    "sum_errors_min = 0\n",
    "for i in range(0,len(pred_list_test)):\n",
    "    sum_errors_min += abs(pred_list_test[i][0]-target_list_test[i][0])\n",
    "    sum_errors_max += abs(pred_list_test[i][1]-target_list_test[i][1])\n",
    "\n",
    "test_result = (sum_errors_min + sum_errors_max) / len(pred_list_test)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute mean square error on training set: 4.877450980392156\n",
      "Absolute mean square error on test set: 455.26715686274497\n",
      "Evaluated\n"
     ]
    }
   ],
   "source": [
    "rf_predictions = dt.predict(X_test)\n",
    "train_rf_predictions = dt.predict(X_train)\n",
    "\n",
    "print(evaluate(train_rf_predictions,y_train,rf_predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 4500 out of 4500 | elapsed:   12.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=4500, n_jobs=-1, oob_score=False,\n",
       "                      random_state=None, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=4500, \n",
    "                               max_features = 'sqrt',\n",
    "                               n_jobs=-1, verbose = 1)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=4)]: Done 4500 out of 4500 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=4)]: Done 4500 out of 4500 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute mean square error on training set: 104.8806179421235\n",
      "Absolute mean square error on test set: 350.520734526403\n",
      "-------------- \n",
      "  Evaluated \n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "rf_predictions = rf.predict(X_test)\n",
    "train_rf_predictions = rf.predict(X_train)\n",
    "\n",
    "print(evaluate(train_rf_predictions,y_train,rf_predictions,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
