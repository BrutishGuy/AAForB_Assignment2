{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# auto reload libraries (you do need to re-import libraries if you make changes)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# base \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "# preprocessing \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# own defined classes/functions\n",
    "from preprocessing.preprocessing import MakeLowerCase\n",
    "from preprocessing.preprocessing import print_missing\n",
    "from preprocessing.preprocessing import calculate_perf\n",
    "from preprocessing.preprocessing import custom_scoring_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global parameters\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Add custum scoring metric: **DONE**\n",
    "- further integrate preprocessing steps from Arnaud\n",
    "- Integerate steps from Victor\n",
    "- fix column touchscreen (there are some mistakes)\n",
    "- fix discrete_gpu\n",
    "- Check screen size (some outlier values)\n",
    "- pixels_y\n",
    "- Integrate custum scoring metric (also when performing the cross validation/grid search)\n",
    "-  Make function that checkts whether prediction of the maximum price are >= predictions of the minimum price\n",
    "- Implement better missing values imputations methods\n",
    "- Add some post processing visualizations:\n",
    "    - feature importance plots\n",
    "    - look at our predictions visually (do the make since?)\n",
    "    - look at the residuals\n",
    "    - Have a look at this especially section 5 for model interpretability ideas\n",
    "    https://christophm.github.io/interpretable-ml-book/pdp.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions training data (340, 22)\n",
      "Dimension validation data (170, 22)\n",
      "Dimension train and validation (all training data) data (510, 22)\n",
      "Dimension test data (222, 20)\n"
     ]
    }
   ],
   "source": [
    "# read in trainig and validation data\n",
    "# use the same data split as we did in R\n",
    "df_train = pd.read_csv(\"../data/train_train.csv\", sep=';')\n",
    "df_val = pd.read_csv(\"../data/train_validation.csv\", sep=';')\n",
    "df_train_val = pd.read_csv(\"../data/train.csv\", sep=';')\n",
    "df_test = pd.read_csv(\"../data/test.csv\", sep=',')\n",
    "\n",
    "print(f'Dimensions training data {df_train.shape}')\n",
    "print(f'Dimension validation data {df_val.shape}')\n",
    "print(f'Dimension train and validation (all training data) data {df_train_val.shape}')\n",
    "print(f'Dimension test data {df_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing count</th>\n",
       "      <th>missing %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>screen_surface</th>\n",
       "      <td>8</td>\n",
       "      <td>2.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_details</th>\n",
       "      <td>5</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu</th>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detachable_keyboard</th>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     missing count  missing %\n",
       "screen_surface                   8       2.35\n",
       "cpu_details                      5       1.47\n",
       "weight                           1       0.29\n",
       "gpu                              1       0.29\n",
       "detachable_keyboard              1       0.29"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_missing(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Pipeline\n",
    "Make a difference between the pre processing steps for\n",
    "- numerical features\n",
    "- categorical features\n",
    "\n",
    "I still don't use all features, since some extra data cleaning is needed on certain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numerical features to pass down the numerical pipeline \n",
    "numerical_features = ['screen_size', 'pixels_x','detachable_keyboard' , \n",
    "                      'ram', 'ssd','storage', 'weight']\n",
    "\n",
    "#Categrical features to pass down the categorical pipeline \n",
    "cateforical_features = ['brand', 'screen_surface','touchscreen', \n",
    "                        'cpu', 'pixels_y', 'discrete_gpu','gpu', 'os']\n",
    "\n",
    "# define all features\n",
    "features = numerical_features + cateforical_features\n",
    "\n",
    "# target variables\n",
    "target = ['min_price','max_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "X_train = df_train[features]\n",
    "y_train = df_train[target]\n",
    "\n",
    "# validation (this is kind our own test set)\n",
    "X_val  = df_val[features]\n",
    "y_val = df_val[target]\n",
    "\n",
    "# train_validation (this is all training data we have) for fitting the model\n",
    "X_train_val = df_train_val[features]\n",
    "y_train_val = df_train_val[target]\n",
    "\n",
    "# test\n",
    "X_test = df_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can add many more and \n",
    "# you can even define custom preprocessing steps like 'MakeLowerCase()'\n",
    "\n",
    "# pipeline  numerical features, \n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# pipeline categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('lowercase', MakeLowerCase()), # lower cases all columns containing strings\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# add both preprocessing pipelines in one pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, cateforical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "## 1) Random Forest\n",
    "\n",
    "### 1.A) Training and parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'mse',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 1,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# define model: I just add some default parameters but you could\n",
    "# also just write: RandomForestRegressor() since we will perform a grid search \n",
    "# to find good hyperparameter values\n",
    "model_rf = RandomForestRegressor(random_state=1)\n",
    "\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(model_rf.get_params())\n",
    "\n",
    "# add to pipeline\n",
    "pipeline_rf = Pipeline(memory=None,\n",
    "              steps=[('preprocessor', preprocessor),\n",
    "                     ('regressor', model_rf)])\n",
    "\n",
    "\n",
    "# add transformation on the target variable, by default power transformation \n",
    "# also performs standardization after performing the power transformation\n",
    "# and back transform to the original space when outputting predictions \n",
    "transformer_target = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "pipeline_rf = TransformedTargetRegressor(regressor=pipeline_rf, \n",
    "                                         transformer=transformer_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 800, stop = 4000, num = 20)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 20)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10,20]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 8]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid_rf = {'regressor__regressor__n_estimators': n_estimators,\n",
    "               'regressor__regressor__max_features': max_features,\n",
    "               'regressor__regressor__max_depth': max_depth,\n",
    "               'regressor__regressor__min_samples_split': min_samples_split,\n",
    "               'regressor__regressor__min_samples_leaf': min_samples_leaf,\n",
    "               'regressor__regressor__bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful articles:\n",
    " - custom scoring metric: https://stackoverflow.com/questions/48468115/how-to-create-a-customized-scoring-function-in-scikit-learn-for-scoring-a-set-of\n",
    " - random parameter search: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 27.8min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 31.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor__regressor__n_estimators': 2821, 'regressor__regressor__min_samples_split': 2, 'regressor__regressor__min_samples_leaf': 1, 'regressor__regressor__max_features': 'sqrt', 'regressor__regressor__max_depth': 31, 'regressor__regressor__bootstrap': False}\n",
      "-303.99585255292095\n"
     ]
    }
   ],
   "source": [
    "# define random search (and narrow down time grid search)\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "                estimator = pipeline_rf, \n",
    "               param_distributions = random_grid_rf, n_iter = 20,  \n",
    "               cv = 10, verbose=2, random_state=1, n_jobs = -1, refit=True,\n",
    "               scoring=make_scorer(custom_scoring_func, greater_is_better=False)\n",
    ")\n",
    "\n",
    "\n",
    "# run grid search and refit with best hyper parameters\n",
    "rf_random_search.fit(X_train, y_train)  \n",
    "print(rf_random_search.best_params_)    \n",
    "print(rf_random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **TODO make a plot that visualizes hyperparameters (maybe kind of heatmap)**\n",
    "- Once we have found good tuning parameters write them down so we don't need to redo this step over and over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_regressor__regressor__n_estimators</th>\n",
       "      <th>param_regressor__regressor__min_samples_split</th>\n",
       "      <th>param_regressor__regressor__min_samples_leaf</th>\n",
       "      <th>param_regressor__regressor__max_features</th>\n",
       "      <th>param_regressor__regressor__max_depth</th>\n",
       "      <th>param_regressor__regressor__bootstrap</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31.665660</td>\n",
       "      <td>1.603202</td>\n",
       "      <td>1.118415</td>\n",
       "      <td>0.380194</td>\n",
       "      <td>2821</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>{'regressor__regressor__n_estimators': 2821, '...</td>\n",
       "      <td>-222.881030</td>\n",
       "      <td>-428.844346</td>\n",
       "      <td>-238.473387</td>\n",
       "      <td>-318.520556</td>\n",
       "      <td>-346.451989</td>\n",
       "      <td>-284.933030</td>\n",
       "      <td>-282.585692</td>\n",
       "      <td>-296.525171</td>\n",
       "      <td>-320.687415</td>\n",
       "      <td>-300.055909</td>\n",
       "      <td>-303.995853</td>\n",
       "      <td>54.447381</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.789808</td>\n",
       "      <td>0.625888</td>\n",
       "      <td>0.352214</td>\n",
       "      <td>0.075838</td>\n",
       "      <td>800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>73</td>\n",
       "      <td>False</td>\n",
       "      <td>{'regressor__regressor__n_estimators': 800, 'r...</td>\n",
       "      <td>-222.548653</td>\n",
       "      <td>-429.397604</td>\n",
       "      <td>-240.887915</td>\n",
       "      <td>-317.111389</td>\n",
       "      <td>-352.580297</td>\n",
       "      <td>-289.100281</td>\n",
       "      <td>-281.296716</td>\n",
       "      <td>-298.086278</td>\n",
       "      <td>-321.930554</td>\n",
       "      <td>-300.316170</td>\n",
       "      <td>-305.325586</td>\n",
       "      <td>54.739279</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.250233</td>\n",
       "      <td>0.332612</td>\n",
       "      <td>0.386171</td>\n",
       "      <td>0.068979</td>\n",
       "      <td>800</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>{'regressor__regressor__n_estimators': 800, 'r...</td>\n",
       "      <td>-236.951240</td>\n",
       "      <td>-435.986898</td>\n",
       "      <td>-242.990144</td>\n",
       "      <td>-324.842966</td>\n",
       "      <td>-346.281604</td>\n",
       "      <td>-268.149599</td>\n",
       "      <td>-282.966164</td>\n",
       "      <td>-298.607383</td>\n",
       "      <td>-324.161850</td>\n",
       "      <td>-304.004172</td>\n",
       "      <td>-306.494202</td>\n",
       "      <td>54.737087</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.781412</td>\n",
       "      <td>2.791092</td>\n",
       "      <td>1.107418</td>\n",
       "      <td>0.157955</td>\n",
       "      <td>2821</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>110</td>\n",
       "      <td>True</td>\n",
       "      <td>{'regressor__regressor__n_estimators': 2821, '...</td>\n",
       "      <td>-253.151490</td>\n",
       "      <td>-447.608041</td>\n",
       "      <td>-259.633286</td>\n",
       "      <td>-306.649343</td>\n",
       "      <td>-343.408493</td>\n",
       "      <td>-276.215412</td>\n",
       "      <td>-292.793195</td>\n",
       "      <td>-381.305741</td>\n",
       "      <td>-331.976059</td>\n",
       "      <td>-284.347724</td>\n",
       "      <td>-317.708878</td>\n",
       "      <td>57.359032</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>53.481692</td>\n",
       "      <td>4.943461</td>\n",
       "      <td>1.348041</td>\n",
       "      <td>0.221395</td>\n",
       "      <td>2315</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>99</td>\n",
       "      <td>True</td>\n",
       "      <td>{'regressor__regressor__n_estimators': 2315, '...</td>\n",
       "      <td>-259.079090</td>\n",
       "      <td>-456.684287</td>\n",
       "      <td>-270.288340</td>\n",
       "      <td>-320.987164</td>\n",
       "      <td>-353.322704</td>\n",
       "      <td>-270.601239</td>\n",
       "      <td>-300.436563</td>\n",
       "      <td>-374.524592</td>\n",
       "      <td>-345.965954</td>\n",
       "      <td>-289.298349</td>\n",
       "      <td>-324.118828</td>\n",
       "      <td>57.636489</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "10      31.665660      1.603202         1.118415        0.380194   \n",
       "7        8.789808      0.625888         0.352214        0.075838   \n",
       "19       8.250233      0.332612         0.386171        0.068979   \n",
       "1       61.781412      2.791092         1.107418        0.157955   \n",
       "12      53.481692      4.943461         1.348041        0.221395   \n",
       "\n",
       "   param_regressor__regressor__n_estimators  \\\n",
       "10                                     2821   \n",
       "7                                       800   \n",
       "19                                      800   \n",
       "1                                      2821   \n",
       "12                                     2315   \n",
       "\n",
       "   param_regressor__regressor__min_samples_split  \\\n",
       "10                                             2   \n",
       "7                                              2   \n",
       "19                                             5   \n",
       "1                                              2   \n",
       "12                                             5   \n",
       "\n",
       "   param_regressor__regressor__min_samples_leaf  \\\n",
       "10                                            1   \n",
       "7                                             1   \n",
       "19                                            1   \n",
       "1                                             1   \n",
       "12                                            2   \n",
       "\n",
       "   param_regressor__regressor__max_features  \\\n",
       "10                                     sqrt   \n",
       "7                                      sqrt   \n",
       "19                                     sqrt   \n",
       "1                                      auto   \n",
       "12                                     auto   \n",
       "\n",
       "   param_regressor__regressor__max_depth  \\\n",
       "10                                    31   \n",
       "7                                     73   \n",
       "19                                    52   \n",
       "1                                    110   \n",
       "12                                    99   \n",
       "\n",
       "   param_regressor__regressor__bootstrap  \\\n",
       "10                                 False   \n",
       "7                                  False   \n",
       "19                                 False   \n",
       "1                                   True   \n",
       "12                                  True   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "10  {'regressor__regressor__n_estimators': 2821, '...        -222.881030   \n",
       "7   {'regressor__regressor__n_estimators': 800, 'r...        -222.548653   \n",
       "19  {'regressor__regressor__n_estimators': 800, 'r...        -236.951240   \n",
       "1   {'regressor__regressor__n_estimators': 2821, '...        -253.151490   \n",
       "12  {'regressor__regressor__n_estimators': 2315, '...        -259.079090   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "10        -428.844346        -238.473387        -318.520556   \n",
       "7         -429.397604        -240.887915        -317.111389   \n",
       "19        -435.986898        -242.990144        -324.842966   \n",
       "1         -447.608041        -259.633286        -306.649343   \n",
       "12        -456.684287        -270.288340        -320.987164   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "10        -346.451989        -284.933030        -282.585692   \n",
       "7         -352.580297        -289.100281        -281.296716   \n",
       "19        -346.281604        -268.149599        -282.966164   \n",
       "1         -343.408493        -276.215412        -292.793195   \n",
       "12        -353.322704        -270.601239        -300.436563   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "10        -296.525171        -320.687415        -300.055909      -303.995853   \n",
       "7         -298.086278        -321.930554        -300.316170      -305.325586   \n",
       "19        -298.607383        -324.161850        -304.004172      -306.494202   \n",
       "1         -381.305741        -331.976059        -284.347724      -317.708878   \n",
       "12        -374.524592        -345.965954        -289.298349      -324.118828   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "10       54.447381                1  \n",
       "7        54.739279                2  \n",
       "19       54.737087                3  \n",
       "1        57.359032                4  \n",
       "12       57.636489                5  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have look at the best hyperparameters and their respective performance (maybe also look at the sd)\n",
    "pd.DataFrame(rf_random_search.cv_results_).sort_values(\n",
    "    by=['mean_test_score'],ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Performance on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'minimum price': 139.54931571067183,\n",
       " 'maximum price': 145.00396316174164,\n",
       " 'total error': 284.55327887241344}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_perf(y_val, rf_random_search.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Post processing\n",
    "\n",
    " - inspect predictions/residuals (make visualisations)\n",
    " - feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) Predictions test data\n",
    "\n",
    "Refit on all training data (using the parameters found on the random search) and submit prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing regressor, total=   9.3s\n"
     ]
    }
   ],
   "source": [
    "# train your final model on all data with best parameters \n",
    "model_rf_final = RandomForestRegressor(\n",
    "     n_estimators=2821, \n",
    "     max_depth=31,\n",
    "     max_features='sqrt',\n",
    "     min_samples_split=2,\n",
    "     min_samples_leaf=1,\n",
    "     n_jobs=-1\n",
    ")\n",
    "# add to pipeline\n",
    "pipeline_rf_final = Pipeline(memory=None,\n",
    "              steps=[('preprocessor', preprocessor),\n",
    "                     ('regressor', model_rf_final)],\n",
    "              verbose=True)\n",
    "\n",
    "# again add transformer for target variable\n",
    "pipeline_rf_final = TransformedTargetRegressor(regressor=pipeline_rf_final, \n",
    "                                         transformer=transformer_target)\n",
    "\n",
    "# fit final model on all training data we have at hand\n",
    "pipeline_rf_final = pipeline_rf_final.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test data\n",
    "rf_pred_test = pipeline_rf_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission format\n",
    "rf_submission_format = pd.DataFrame.from_dict(\n",
    " {'ID':df_test['id'].values,\n",
    " 'MIN':rf_pred_test[:,0],\n",
    " 'MAX':rf_pred_test[:,1]}).set_index('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv\n",
    "rf_submission_format.to_csv('../output/predictions_test/rf_python.csv' ,\n",
    "                            header=True, index=True, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
